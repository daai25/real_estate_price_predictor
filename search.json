[
  {
    "objectID": "md-templates/project_charta_template.html",
    "href": "md-templates/project_charta_template.html",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Formulate the problem and important information about the domain and/or business area in which the product is to be developed: What exactly is the problem and the expected benefit of the project? Why should we undertake this effort?\nThis includes a summary of the most important findings from the user analysis: relevant segments and user groups. Describe the problems and needs of the users of the product to be developed.\nStakeholders: List the people involved in and affected by the project. Describe their goals and relationships with each other. Visualisation in the form of a stakeholder map can provide a quick overview.\nYou can reference more detailed analyses such as individual “personas” or interviews in separate documents in the appendix.\n\n\n\nDescribe the available resources (personnel, material, (software) tools, infrastructure, etc.) and time as well as restrictions and constraints. Possible risks that may arise during the project are also identified.\n\n\n\nWhen is the project successful from a client/stakeholder perspective: Formulate (qualitative) objectives, wherever possible, corresponding key metrics and the target values to be achieved within the project.\nIt is also often helpful to specify what is explicitly excluded from the project objectives (out of scope).\n\n\n\nMap the problem definition, datasets to be used and primary objective onto a data mining task, e.g.:\n\nClassification\nRegression\nClustering\nOutlier Detection\nAssociation rule learning (market basket analysis)\nRecommender System\nVisualisation\n…\n\nAlong with the definition of the actual technical problem (category) to be solved, the project goals must be mapped onto quitable quantitative metrics and corresponding target values. For example, for a classification task one might specify an F-score of 0.9 as a minimal requirement for an acceptable solution.\nSuch a requirement should be aligned with the overall project goals and/or literature references or justified by other references, respectively.\n\n\n\nDivide the project into individual phases, describe them briefly and draw up a preliminary timetable, e.g. as a Gantt chart:\ngantt\n    title A Gantt Diagram\n    dateFormat YYYY-MM-DD\n    tickInterval 5day\n    section Project Understanding\n        Define problem,     :a1, 2024-07-01, 1d\n        Determine project goals     :a2, 2024-07-01, 1d\n        List available resources     :a3, 2024-07-02, 1d\n        Set data mining goals    :a4, 2024-07-03, 1d\n        Create project plan    :a5, 2024-07-03, 1d\n        Project checkpoint: milestone, m1, 2024-07-04, 4m\n    section Data Acquisition and Exploration\n        Acquire data :a6, 2024-07-02, 2d\n        Exploratory data analysis   :a7, 2024-07-03, 2d\n        \n    section Modelling\n        Create initial model   :a8, 2024-07-09, 1d\n        Additional feature engineering :a9, 2024-07-10, 1d\n        Prepare modelling report :a10, 2024-07-10, 2h\n    section Evaluation\n        Prepare presentation :a10, 2024-07-10, 2h\n        Project presentation : milestone, m2, 2024-07-11, 4m\nSee Mermaid syntax for Gantt charts.\n\n\n\nList the people involved in the development work here with their role titles, tasks and contact details"
  },
  {
    "objectID": "md-templates/project_charta_template.html#problem-definition",
    "href": "md-templates/project_charta_template.html#problem-definition",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Formulate the problem and important information about the domain and/or business area in which the product is to be developed: What exactly is the problem and the expected benefit of the project? Why should we undertake this effort?\nThis includes a summary of the most important findings from the user analysis: relevant segments and user groups. Describe the problems and needs of the users of the product to be developed.\nStakeholders: List the people involved in and affected by the project. Describe their goals and relationships with each other. Visualisation in the form of a stakeholder map can provide a quick overview.\nYou can reference more detailed analyses such as individual “personas” or interviews in separate documents in the appendix."
  },
  {
    "objectID": "md-templates/project_charta_template.html#situation-assessment",
    "href": "md-templates/project_charta_template.html#situation-assessment",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Describe the available resources (personnel, material, (software) tools, infrastructure, etc.) and time as well as restrictions and constraints. Possible risks that may arise during the project are also identified."
  },
  {
    "objectID": "md-templates/project_charta_template.html#project-goals-and-success-criteria",
    "href": "md-templates/project_charta_template.html#project-goals-and-success-criteria",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "When is the project successful from a client/stakeholder perspective: Formulate (qualitative) objectives, wherever possible, corresponding key metrics and the target values to be achieved within the project.\nIt is also often helpful to specify what is explicitly excluded from the project objectives (out of scope)."
  },
  {
    "objectID": "md-templates/project_charta_template.html#data-mining-goals",
    "href": "md-templates/project_charta_template.html#data-mining-goals",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Map the problem definition, datasets to be used and primary objective onto a data mining task, e.g.:\n\nClassification\nRegression\nClustering\nOutlier Detection\nAssociation rule learning (market basket analysis)\nRecommender System\nVisualisation\n…\n\nAlong with the definition of the actual technical problem (category) to be solved, the project goals must be mapped onto quitable quantitative metrics and corresponding target values. For example, for a classification task one might specify an F-score of 0.9 as a minimal requirement for an acceptable solution.\nSuch a requirement should be aligned with the overall project goals and/or literature references or justified by other references, respectively."
  },
  {
    "objectID": "md-templates/project_charta_template.html#project-plan",
    "href": "md-templates/project_charta_template.html#project-plan",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Divide the project into individual phases, describe them briefly and draw up a preliminary timetable, e.g. as a Gantt chart:\ngantt\n    title A Gantt Diagram\n    dateFormat YYYY-MM-DD\n    tickInterval 5day\n    section Project Understanding\n        Define problem,     :a1, 2024-07-01, 1d\n        Determine project goals     :a2, 2024-07-01, 1d\n        List available resources     :a3, 2024-07-02, 1d\n        Set data mining goals    :a4, 2024-07-03, 1d\n        Create project plan    :a5, 2024-07-03, 1d\n        Project checkpoint: milestone, m1, 2024-07-04, 4m\n    section Data Acquisition and Exploration\n        Acquire data :a6, 2024-07-02, 2d\n        Exploratory data analysis   :a7, 2024-07-03, 2d\n        \n    section Modelling\n        Create initial model   :a8, 2024-07-09, 1d\n        Additional feature engineering :a9, 2024-07-10, 1d\n        Prepare modelling report :a10, 2024-07-10, 2h\n    section Evaluation\n        Prepare presentation :a10, 2024-07-10, 2h\n        Project presentation : milestone, m2, 2024-07-11, 4m\nSee Mermaid syntax for Gantt charts."
  },
  {
    "objectID": "md-templates/project_charta_template.html#roles-and-contact-details",
    "href": "md-templates/project_charta_template.html#roles-and-contact-details",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "List the people involved in the development work here with their role titles, tasks and contact details"
  },
  {
    "objectID": "md-templates/modelling_report.html",
    "href": "md-templates/modelling_report.html",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "The report should summarise the details of the modelling activities, e.g. machine learning experiments.\n\n\n\nAim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed\n\n\n\n\nOverview of the models used and/or implemented and their configurations\n\nDetailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.)\nGraphical representation of the modelling pipeline\nIf applicable: link to the code of the modelling pipeline, version information in code repository, configuration files\nIf possible, links to the artefacts of the executed modelling pipeline (training experiment)\nLink to the literature in which the model/method is described\nHyperparameters\n\n\n\n\nKey figures dependent on the model and modelling objective\n\nRMSD, ROC/Lift-Charts, AUC, Confusion Matrix, Accuracy, Precision, Recall\nCoherence, Perplexity, …\nIf applicable: analyses/plots of (hyper)parameter screenings\n\n\n\n\n\nIf applicable: Results from the application of “explanatory models”\nWere the modelling objectives achieved?\nThe findings resulting from the modelling phase: can the project objective be achieved with the results from the modelling phase?\nHow can the findings be used? Are there any limitations?\n\n\n\n\n\nConclusions of the key findings from the modelling phase\nDiscussion about limitations\nProposal for extensions and further work\nProposal for the deployment of the generated insights/model"
  },
  {
    "objectID": "md-templates/modelling_report.html#initial-situation",
    "href": "md-templates/modelling_report.html#initial-situation",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Aim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed"
  },
  {
    "objectID": "md-templates/modelling_report.html#model-descriptions",
    "href": "md-templates/modelling_report.html#model-descriptions",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Overview of the models used and/or implemented and their configurations\n\nDetailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.)\nGraphical representation of the modelling pipeline\nIf applicable: link to the code of the modelling pipeline, version information in code repository, configuration files\nIf possible, links to the artefacts of the executed modelling pipeline (training experiment)\nLink to the literature in which the model/method is described\nHyperparameters"
  },
  {
    "objectID": "md-templates/modelling_report.html#results",
    "href": "md-templates/modelling_report.html#results",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Key figures dependent on the model and modelling objective\n\nRMSD, ROC/Lift-Charts, AUC, Confusion Matrix, Accuracy, Precision, Recall\nCoherence, Perplexity, …\nIf applicable: analyses/plots of (hyper)parameter screenings"
  },
  {
    "objectID": "md-templates/modelling_report.html#model-interpretation",
    "href": "md-templates/modelling_report.html#model-interpretation",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "If applicable: Results from the application of “explanatory models”\nWere the modelling objectives achieved?\nThe findings resulting from the modelling phase: can the project objective be achieved with the results from the modelling phase?\nHow can the findings be used? Are there any limitations?"
  },
  {
    "objectID": "md-templates/modelling_report.html#conclusions-and-next-steps",
    "href": "md-templates/modelling_report.html#conclusions-and-next-steps",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Conclusions of the key findings from the modelling phase\nDiscussion about limitations\nProposal for extensions and further work\nProposal for the deployment of the generated insights/model"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About This Documentation",
    "section": "",
    "text": "The Data Science Process [1]\n\n\n\n\n\n\nReferences\n\n1. Doemer D, Kempf M. Is it ops that make data science scientific? Archives of Data Science, Series A (Online First). 2022;8(2):12 S.",
    "crumbs": [
      "About This Documentation"
    ]
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "This protocol documents the decisions taken at the evaluation stage of the Real Estate Price Predictor project. The evaluation was conducted in a team workshop on 2025-07-24, with the aim of assessing whether the results of the data mining phase meet user needs and whether to proceed to deployment.\n\n\n\n\n\nName\nRole\n\n\n\n\nJosh Richter\nData Engineer\n\n\nAlessandro Mazzeo\nML Developer\n\n\nAntonie Michael Verdile\nFull Stack Developer\n\n\nEnmanuel Lizardo\nData Scientist\n\n\n\n\n\n\n\n\nYes.\nThe developed Random Forest models achieved high predictive performance, surpassing the minimum success criteria outlined in the Project Charta (R² &gt; 0.75, MAE &lt; 300 CHF). The models provide accurate, interpretable predictions for both rental and purchase markets and are ready for integration into a dashboard for user interaction.\n\n\n\nYes.\nThe team unanimously decided to proceed with deployment and further development. The results were deemed robust and aligned with the project goals.\n\n\n\nDeployment will include: - Integrating the trained Random Forest models into a web-based user interface. - Backend implementation of the prediction API. - Monitoring and maintenance plan for the deployed models. - Documentation of model assumptions and limitations for transparency.\nPlanned timeline: see Project Gantt Chart — Phase 4: Visualization (2025-07-24 through 2025-07-28).\n\n\n\nNot required at this stage. However, the following future enhancements were noted: - Augment data with external sources such as demographic and transport data. - Improve clustering methods by incorporating domain-specific ontologies. - Reassess governance and ethics as data privacy regulations evolve.\n\n\n\n\n\nPresentation slides (PDF)\n\n\n\n\nThe final product to be deployed is a web-based prediction dashboard that: - Allows users to input property features and obtain real-time price predictions. - Visualizes prediction confidence and key feature contributions. - Offers insights into market segmentation (via clusters) and trends.\n\n\n\nThe team acknowledges the limitations identified in the modelling phase, particularly: - Market dynamics not yet accounted for. - Dependence on scraped data quality and completeness.\nThese points will be addressed in future project iterations.",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "evaluation.html#participants",
    "href": "evaluation.html#participants",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "Name\nRole\n\n\n\n\nJosh Richter\nData Engineer\n\n\nAlessandro Mazzeo\nML Developer\n\n\nAntonie Michael Verdile\nFull Stack Developer\n\n\nEnmanuel Lizardo\nData Scientist",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "evaluation.html#evaluation-summary",
    "href": "evaluation.html#evaluation-summary",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "Yes.\nThe developed Random Forest models achieved high predictive performance, surpassing the minimum success criteria outlined in the Project Charta (R² &gt; 0.75, MAE &lt; 300 CHF). The models provide accurate, interpretable predictions for both rental and purchase markets and are ready for integration into a dashboard for user interaction.\n\n\n\nYes.\nThe team unanimously decided to proceed with deployment and further development. The results were deemed robust and aligned with the project goals.\n\n\n\nDeployment will include: - Integrating the trained Random Forest models into a web-based user interface. - Backend implementation of the prediction API. - Monitoring and maintenance plan for the deployed models. - Documentation of model assumptions and limitations for transparency.\nPlanned timeline: see Project Gantt Chart — Phase 4: Visualization (2025-07-24 through 2025-07-28).\n\n\n\nNot required at this stage. However, the following future enhancements were noted: - Augment data with external sources such as demographic and transport data. - Improve clustering methods by incorporating domain-specific ontologies. - Reassess governance and ethics as data privacy regulations evolve.",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "evaluation.html#workshop-materials",
    "href": "evaluation.html#workshop-materials",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "Presentation slides (PDF)",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "evaluation.html#envisioned-product",
    "href": "evaluation.html#envisioned-product",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "The final product to be deployed is a web-based prediction dashboard that: - Allows users to input property features and obtain real-time price predictions. - Visualizes prediction confidence and key feature contributions. - Offers insights into market segmentation (via clusters) and trends.",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "evaluation.html#notes",
    "href": "evaluation.html#notes",
    "title": "Evaluation Protocol",
    "section": "",
    "text": "The team acknowledges the limitations identified in the modelling phase, particularly: - Market dynamics not yet accounted for. - Dependence on scraped data quality and completeness.\nThese points will be addressed in future project iterations.",
    "crumbs": [
      "Evaluation Protocol"
    ]
  },
  {
    "objectID": "data_report.html",
    "href": "data_report.html",
    "title": "Data Report",
    "section": "",
    "text": "All information on the data used in the project is compiled in this data report to ensure the traceability and reproducibility of the results and to enable a systematic expansion of the database.\nTypically, in the exploratory analysis of the acquired raw data, quality and other issues are identified, which require pre-processing, merging of individual datasets and feature engineering into processed datasets. Therefore, this report provides a separate section for the processed data, which then serves as a starting point for the modelling activities.",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#raw-data",
    "href": "data_report.html#raw-data",
    "title": "Data Report",
    "section": "Raw Data",
    "text": "Raw Data\n\nOverview Raw Datasets\n\n\n\nName\nSource\nStorage Location\n\n\n\n\nFlatfox Listings\nflatfox.ch (rental offers)\noutput_flatfox.json\n\n\nUrbanHome Rentals\nurbanhome.ch (rental offers)\noutput_urbanhome.json\n\n\nUrbanHome Sales\nurbanhome.ch (buy offers)\noutput_urbanhome_buy.json\n\n\n\n\n\nDetails Dataset 1: Flatfox Listings\n\nDescription: Contains real estate rental listings scraped from flatfox.ch, including title, address, ZIP code, city, price, rooms, area in sqm, availability, etc.\nSource/Provider: Flatfox.ch\nProcurement: Collected using custom Python scraper using Selenium and BeautifulSoup\nReproducibility: Team members can rerun scraping using the script in the GitHub repository under Flatfox Scraper\nLegal: Only publicly accessible data is used; terms of use must be checked regularly.\nGovernance: Business-relevant, anonymized\nVariable roles:\n\nDependent: price\nIndependent: rooms, area_sqm, floor, zip_code, has_balcony, city\n\n\n\n\nDetails Dataset 2: UrbanHome Rentals\n\nDescription: Rental property listings collected from urbanhome.ch, with attributes such as location, price, size, and availability.\nSource/Provider: UrbanHome.ch\nProcurement: Scraped using a Selenium-based Python script; similar structure to Flatfox data\nReproducibility: Fully reproducible via the Urbanhome Scraper script in the repository\nLegal: Publicly available data; periodically verify platform terms of use\nGovernance: Public and business-relevant\nVariable roles:\n\nDependent: price\nIndependent: rooms, area_sqm, floor, zip_code, has_balcony, city\n\n\n\n\nDetails Dataset 3: UrbanHome Sales\n\nDescription: Contains residential real estate listings offered for sale on urbanhome.ch, with structured fields similar to rental data.\nSource/Provider: UrbanHome.ch\nProcurement: Collected via a custom web scraping script urbanhome_buy_scraper.py\nReproducibility: Executable with documented script under the Urbanhome Scraper\nLegal: Scraped from publicly accessible offers; non-personal data\nGovernance: Public, business-relevant\nVariable roles:\n\nDependent: price\nIndependent: rooms, area_sqm, zip_code, city, has_balcony, floor\n\n\n\n\nData Catalogue (Flatfox and Urbanhome Listings)\n\n\n\n\n\n\n\n\n\n\nColumn Index\nColumn Name\nDatatype\nValues / Validation\nDescription\n\n\n\n\n1\ntitle\nstring\n-\nTitle of the listing\n\n\n2\naddress\nstring\n-\nStreet address\n\n\n3\nzip_code\nint\n1000 - 9999\nSwiss ZIP code\n\n\n4\ncity\nstring\n-\nCity name\n\n\n5\nregion\nstring\ne.g. ZH, BE\nCanton abbreviation\n\n\n6\nprice\nfloat\n&gt; 0\nMonthly rent or price\n\n\n7\nrooms\nfloat\n0.5 - 10\nNumber of rooms\n\n\n8\nfloor\nint\n&gt;= 0\nFloor number\n\n\n9\narea_sqm\nfloat\n&gt; 0\nLiving space in square meters\n\n\n10\navailability_date\ndatetime\nISO 8601\nStart date for availability\n\n\n11\nhas_balcony\nboolean\ntrue / false\nWhether the apartment has a balcony\n\n\n12\ndescription\nstring\n-\nFull text of the listing\n\n\n13\nimage_urls\nlist[string]\nValid URLs\nImage URLs\n\n\n14\nis_rental\nboolean\ntrue\nIndicates rental properties",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#data-quality",
    "href": "data_report.html#data-quality",
    "title": "Data Report",
    "section": "Data Quality",
    "text": "Data Quality\nDuring initial exploratory analysis, the following issues were identified:\n\nSome listings contain missing price, area_sqm, or rooms values.\nInconsistencies in zip_code formats (some as strings, some as ints)\nMixed granularity in rooms values (e.g. 1 vs 1.0 vs 1.5 vs 3 ½)\nIncomplete or overly long free-text description fields\nDuplicate or nearly duplicate entries (due to reposts or scrape overlaps)\n\nThese issues required cleaning steps such as deduplication, type normalization, filtering and imputation.",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#exploratory-data-analysis-eda",
    "href": "data_report.html#exploratory-data-analysis-eda",
    "title": "Data Report",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nTo better understand the data structure and identify patterns, we conducted an exploratory analysis on the cleaned listings.\n\n📉 Price Distribution\n\n\n\n📏 Area Distribution\n\n\n\n🛏 Room Count Distribution\n\n\n\n💰 Price per m² Distribution\n\n\n\n🔗 Feature Correlation Heatmap\n\n\n\n🌍 Average Price by Region\n\n\n\n📝 Description Length vs. Price\n\n\n\n🧭 3D Plot: Price per m² by Canton and Area",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#processed-data",
    "href": "data_report.html#processed-data",
    "title": "Data Report",
    "section": "Processed Data",
    "text": "Processed Data\n\nOverview Processed Datasets\n\n\n\nName\nSource\nStorage Location\n\n\n\n\nCleaned Listings\nAggregated & cleaned\ncleaned_data.json\n\n\n\n\n\nDetails Processed Dataset 1: Cleaned Listings\n\nDescription: Cleaned and unified dataset combining all rental listings with harmonized schema. Unused fields removed, null values handled.\nProcessing steps:\n\nMerging listings from Flatfox and UrbanHome\nFiltering to retain only listings with all essential fields (price, rooms, area_sqm, zip_code)\nNormalizing values (e.g., numeric parsing, boolean flags)\nFeature engineering (e.g., price_per_sqm, encoded ZIP region)\n\nAccess: Available in cleaned_data.json. Generated using data_preparation.py script in project repo.\n\n\n\nData Catalogue (Cleaned Listings)\n\n\n\n\n\n\n\n\n\n\nColumn Index\nColumn Name\nDatatype\nValues / Validation\nDescription\n\n\n\n\n1\ntitle\nstring\n-\nListing title\n\n\n2\naddress\nstring\n-\nStreet address\n\n\n3\nzip_code\nint\n1000–9999\nSwiss postal code\n\n\n4\ncity\nstring\n-\nCity name\n\n\n5\nregion\nstring\nZH, BE, etc.\nCanton abbreviation\n\n\n6\nprice\nfloat\n&gt; 0\nRent price or sales price\n\n\n7\nrooms\nfloat\n&gt; 0\nNumber of rooms\n\n\n8\nfloor\nint\n&gt;= 0\nFloor number\n\n\n9\narea_sqm\nfloat\n&gt; 0\nLiving area in m²\n\n\n10\navailability_date\ndatetime\nISO 8601\nWhen available\n\n\n11\nhas_balcony\nboolean\ntrue / false\nBalcony presence\n\n\n12\ndescription\nstring\n-\nListing description\n\n\n13\nimage_urls\nlist[string]\nValid URLs\nImage references\n\n\n14\nis_rental\nboolean\ntrue\nRental listing indicator",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#optional-entity-relationship-diagram",
    "href": "data_report.html#optional-entity-relationship-diagram",
    "title": "Data Report",
    "section": "(Optional) Entity Relationship Diagram",
    "text": "(Optional) Entity Relationship Diagram\nNot applicable – data is stored as flat JSON records.",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "project_charta.html",
    "href": "project_charta.html",
    "title": "Project Charta",
    "section": "",
    "text": "What is the problem?\nThe challenge is to develop a machine learning system that predicts the rental or selling price of residential properties. Currently, renters and buyers rely on manual and often subjective methods to assess property value. This leads to inefficiencies, missed opportunities, and mispriced listings.\nDomain/Business Area\nThe project operates within the Swiss real estate market, involving rental agencies, private buyers and sellers, and expanding corporations. Real estate platforms like UrbanHome, ImmoScout24 and others are relevant sources.\nExpected Benefit\nThe tool will help users, especially renters and buyers, find properties with the best price-to-quality ratio. It provides landlords and sellers with better pricing strategies and enables data-driven decision-making.\nWhy this effort?\nAn ML-powered property price predictor can dramatically reduce the time and uncertainty involved in the property search process. By learning from real data, the model helps stakeholders make informed choices aligned with their financial and lifestyle needs.\nStakeholders\n\n\n\n\n\n\n\n\n\nStakeholder\nRole\nGoal\nRelationship\n\n\n\n\nBuyers/Renters\nUsers of the predictor\nFind the best value-for-money home\nInterested in accuracy and usability\n\n\nSellers/Landlords\nInput providers and users\nPrice fairly and competitively\nInterested in fair predictions\n\n\nProject Team\nDevelopers and analysts\nBuild the system within 4 weeks\nProvides value to both user groups\n\n\nData Sources\nReal estate websites (UrbanHome etc.)\nProvide structured/unstructured data\nData dependency\n\n\n\n\n\n\nResources\n- Personnel: 3 people\n- Software/Tools: VS Code, Python, SQLite, HTML, JS, CSS\n- Infrastructure: Local development environments\n- Data Sources: Real estate listing websites\n- Time: 4 weeks (192 hours total)\nConstraints\n- All data must be acquired from public websites via scraping.\n- Must handle dynamic content, inconsistent formats, and ensure data privacy and legality.\nRestrictions\n- Limited project time and small team size.\n- No access to private or premium datasets.\nRisks\n- Lack of deep experience in ML model optimization.\n- Time constraints may limit dashboard and DL integration quality.\n\n\n\nQualitative Goals\n- Develop a working ML model that predicts property prices.\n- Visualize the results in a user-friendly dashboard.\n- Enhance accuracy with tabular and image-based features.\nSuccess Criteria and Metrics\n- At least 1,000 unique properties scraped and processed.\n- Classical regression model achieves MAE &lt; 300 CHF or R² &gt; 0.75.\n- Dashboard allows users to query a property and receive a predicted price.\n- Integration of deep learning features shows performance improvement over baseline.\nOut of Scope\n- Commercial deployment\n- Legal contracts, compliance, and regulatory integration\n- Mobile applications\n\n\n\nTask Mapping\n- Primary Task: Regression, to predict continuous property prices.\n- Subtasks: - Classification, for image room types or amenity presence - Visualization, for dashboard output and EDA\nDatasets to Be Used\n- Scraped tabular data (price, rooms, size, location, etc.)\n- Downloaded property images\n- Optionally enriched with geographic/statistical data from APIs\nTarget Metrics\n- Regression:\n- MAE &lt; 300 CHF\n- R² &gt; 0.75\n- Classification (images):\n- Accuracy &gt; 0.8\n- F1-score &gt; 0.75 (for multi-label classification)\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\nTasks\nContact\n\n\n\n\nJosh Richter\nData Engineer\nWeb scraping, data cleaning, DB design\nrichtjos@mail.gvsu.edu\n\n\nAlessandro Mazzeo\nML Developer\nFeature engineering, model training, evaluation\nmazzale@students.zhaw.ch\n\n\nAntonio Michael Verdile\nFull Stack Dev\nDashboard development, ML integration, UI/UX design\nverdiant@students.zhaw.ch\n\n\nEnmanuel Lizardo\nData Scientist\nAnalytics, research, data visualisation\nlizardoe@mail.gvsu.edu\n\n\n\n\n\n\n\n\ngantt\n    title Project Plan\n    dateFormat  YYYY-MM-DD\n    tickInterval 5day\n    todayMarker off\n    axisFormat  %d.%m\n\n    section Phase 1: \n    Data Eng.           :crit,   gh1, 2025-06-30, 4d\n    Project Charta      :        pc1, 2025-06-30, 1d\n    Data Scraping       :        ds1, 2025-07-01, 2d\n    DB Design           :        db1, 2025-07-02, 1d\n    Data Insertion      :        di1, 2025-07-03, 1d\n\n    section Phase 2: \n    ML                  :crit,   cd1, 2025-07-07, 4d\n    Data Prep           :        dp1, 2025-07-07, 1d\n    EDA                 :        ed,  2025-07-07, 2d\n    Preprocessing       :        pp1, 2025-07-08, 2d\n    Modeling            :        mod, 2025-07-09, 1d\n    Evaluation          :        ev1, 2025-07-10, 1d\n\n    section Phase 3: \n    DL                   :crit,   ab1, 2025-07-14, 4d\n    Image Labeling      :        il1, 2025-07-14, 1d\n    Model Building      :        mb1, 2025-07-15, 2d\n    Training            :        tr1, 2025-07-16, 1d\n    Feature Integration :        fi1, 2025-07-17, 1d\n\n    section Phase 4: \n    Visualisation       :crit,   ef1, 2025-07-24, 4d\n    Dashboard           :        dd1, 2025-07-24, 2d\n    Data Visualisation  :        dv1, 2025-07-25, 1d\n    Prediction Interface:        pi1, 2025-07-25, 1d\n    Backend Integration :        bi1, 2025-07-25, 1d\n    Presenation         :        bi1, 2025-07-26, 1d",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#problem-definition",
    "href": "project_charta.html#problem-definition",
    "title": "Project Charta",
    "section": "",
    "text": "What is the problem?\nThe challenge is to develop a machine learning system that predicts the rental or selling price of residential properties. Currently, renters and buyers rely on manual and often subjective methods to assess property value. This leads to inefficiencies, missed opportunities, and mispriced listings.\nDomain/Business Area\nThe project operates within the Swiss real estate market, involving rental agencies, private buyers and sellers, and expanding corporations. Real estate platforms like UrbanHome, ImmoScout24 and others are relevant sources.\nExpected Benefit\nThe tool will help users, especially renters and buyers, find properties with the best price-to-quality ratio. It provides landlords and sellers with better pricing strategies and enables data-driven decision-making.\nWhy this effort?\nAn ML-powered property price predictor can dramatically reduce the time and uncertainty involved in the property search process. By learning from real data, the model helps stakeholders make informed choices aligned with their financial and lifestyle needs.\nStakeholders\n\n\n\n\n\n\n\n\n\nStakeholder\nRole\nGoal\nRelationship\n\n\n\n\nBuyers/Renters\nUsers of the predictor\nFind the best value-for-money home\nInterested in accuracy and usability\n\n\nSellers/Landlords\nInput providers and users\nPrice fairly and competitively\nInterested in fair predictions\n\n\nProject Team\nDevelopers and analysts\nBuild the system within 4 weeks\nProvides value to both user groups\n\n\nData Sources\nReal estate websites (UrbanHome etc.)\nProvide structured/unstructured data\nData dependency",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#situation-assessment",
    "href": "project_charta.html#situation-assessment",
    "title": "Project Charta",
    "section": "",
    "text": "Resources\n- Personnel: 3 people\n- Software/Tools: VS Code, Python, SQLite, HTML, JS, CSS\n- Infrastructure: Local development environments\n- Data Sources: Real estate listing websites\n- Time: 4 weeks (192 hours total)\nConstraints\n- All data must be acquired from public websites via scraping.\n- Must handle dynamic content, inconsistent formats, and ensure data privacy and legality.\nRestrictions\n- Limited project time and small team size.\n- No access to private or premium datasets.\nRisks\n- Lack of deep experience in ML model optimization.\n- Time constraints may limit dashboard and DL integration quality.",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#project-goals-and-success-criteria",
    "href": "project_charta.html#project-goals-and-success-criteria",
    "title": "Project Charta",
    "section": "",
    "text": "Qualitative Goals\n- Develop a working ML model that predicts property prices.\n- Visualize the results in a user-friendly dashboard.\n- Enhance accuracy with tabular and image-based features.\nSuccess Criteria and Metrics\n- At least 1,000 unique properties scraped and processed.\n- Classical regression model achieves MAE &lt; 300 CHF or R² &gt; 0.75.\n- Dashboard allows users to query a property and receive a predicted price.\n- Integration of deep learning features shows performance improvement over baseline.\nOut of Scope\n- Commercial deployment\n- Legal contracts, compliance, and regulatory integration\n- Mobile applications",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#data-mining-goals",
    "href": "project_charta.html#data-mining-goals",
    "title": "Project Charta",
    "section": "",
    "text": "Task Mapping\n- Primary Task: Regression, to predict continuous property prices.\n- Subtasks: - Classification, for image room types or amenity presence - Visualization, for dashboard output and EDA\nDatasets to Be Used\n- Scraped tabular data (price, rooms, size, location, etc.)\n- Downloaded property images\n- Optionally enriched with geographic/statistical data from APIs\nTarget Metrics\n- Regression:\n- MAE &lt; 300 CHF\n- R² &gt; 0.75\n- Classification (images):\n- Accuracy &gt; 0.8\n- F1-score &gt; 0.75 (for multi-label classification)",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#roles-and-contact-details",
    "href": "project_charta.html#roles-and-contact-details",
    "title": "Project Charta",
    "section": "",
    "text": "Name\nRole\nTasks\nContact\n\n\n\n\nJosh Richter\nData Engineer\nWeb scraping, data cleaning, DB design\nrichtjos@mail.gvsu.edu\n\n\nAlessandro Mazzeo\nML Developer\nFeature engineering, model training, evaluation\nmazzale@students.zhaw.ch\n\n\nAntonio Michael Verdile\nFull Stack Dev\nDashboard development, ML integration, UI/UX design\nverdiant@students.zhaw.ch\n\n\nEnmanuel Lizardo\nData Scientist\nAnalytics, research, data visualisation\nlizardoe@mail.gvsu.edu\n\n\n\n\n\n\n\n\ngantt\n    title Project Plan\n    dateFormat  YYYY-MM-DD\n    tickInterval 5day\n    todayMarker off\n    axisFormat  %d.%m\n\n    section Phase 1: \n    Data Eng.           :crit,   gh1, 2025-06-30, 4d\n    Project Charta      :        pc1, 2025-06-30, 1d\n    Data Scraping       :        ds1, 2025-07-01, 2d\n    DB Design           :        db1, 2025-07-02, 1d\n    Data Insertion      :        di1, 2025-07-03, 1d\n\n    section Phase 2: \n    ML                  :crit,   cd1, 2025-07-07, 4d\n    Data Prep           :        dp1, 2025-07-07, 1d\n    EDA                 :        ed,  2025-07-07, 2d\n    Preprocessing       :        pp1, 2025-07-08, 2d\n    Modeling            :        mod, 2025-07-09, 1d\n    Evaluation          :        ev1, 2025-07-10, 1d\n\n    section Phase 3: \n    DL                   :crit,   ab1, 2025-07-14, 4d\n    Image Labeling      :        il1, 2025-07-14, 1d\n    Model Building      :        mb1, 2025-07-15, 2d\n    Training            :        tr1, 2025-07-16, 1d\n    Feature Integration :        fi1, 2025-07-17, 1d\n\n    section Phase 4: \n    Visualisation       :crit,   ef1, 2025-07-24, 4d\n    Dashboard           :        dd1, 2025-07-24, 2d\n    Data Visualisation  :        dv1, 2025-07-25, 1d\n    Prediction Interface:        pi1, 2025-07-25, 1d\n    Backend Integration :        bi1, 2025-07-25, 1d\n    Presenation         :        bi1, 2025-07-26, 1d",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "modelling_report.html",
    "href": "modelling_report.html",
    "title": "Modelling Report",
    "section": "",
    "text": "The goal of this modelling phase was to build predictive models for real estate pricing, both for rental and purchase markets. This objective aligns with the Data Mining Goals defined in the project charta:\n- Predict the price of a property based on structured features\n- Evaluate multiple models to select the best-performing one\n- Interpret model outputs and determine feasibility for deployment\n\n\n\nWe used the cleaned and preprocessed dataset described in the Data Report. The dataset includes features such as: - Property characteristics (e.g. size, number of rooms, floor) - Location information (ZIP code, city, longitude/latitude clusters) - Categorical indicators extracted from property descriptions (e.g. keywords)\nTarget variables: - price_rent (rental market) - price_purchase (purchase market)\nReferences: - See Data Report for preprocessing and feature engineering details.\n\n\n\nThree models were tested and compared: - Linear Regression (Baseline) - Random Forest Regressor - XGBoost Regressor\nAll models were implemented using scikit-learn and xgboost in Python 3.11.\nThe final selected model was Random Forest, based on its superior performance across evaluation metrics and residual analysis.",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#aim-of-the-modelling",
    "href": "modelling_report.html#aim-of-the-modelling",
    "title": "Modelling Report",
    "section": "",
    "text": "The goal of this modelling phase was to build predictive models for real estate pricing, both for rental and purchase markets. This objective aligns with the Data Mining Goals defined in the project charta:\n- Predict the price of a property based on structured features\n- Evaluate multiple models to select the best-performing one\n- Interpret model outputs and determine feasibility for deployment",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#data-sets-and-features",
    "href": "modelling_report.html#data-sets-and-features",
    "title": "Modelling Report",
    "section": "",
    "text": "We used the cleaned and preprocessed dataset described in the Data Report. The dataset includes features such as: - Property characteristics (e.g. size, number of rooms, floor) - Location information (ZIP code, city, longitude/latitude clusters) - Categorical indicators extracted from property descriptions (e.g. keywords)\nTarget variables: - price_rent (rental market) - price_purchase (purchase market)\nReferences: - See Data Report for preprocessing and feature engineering details.",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#model-overview",
    "href": "modelling_report.html#model-overview",
    "title": "Modelling Report",
    "section": "",
    "text": "Three models were tested and compared: - Linear Regression (Baseline) - Random Forest Regressor - XGBoost Regressor\nAll models were implemented using scikit-learn and xgboost in Python 3.11.\nThe final selected model was Random Forest, based on its superior performance across evaluation metrics and residual analysis.",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#software-libraries",
    "href": "modelling_report.html#software-libraries",
    "title": "Modelling Report",
    "section": "Software & Libraries",
    "text": "Software & Libraries\n\nPython 3.11\nscikit-learn==1.4.2\nxgboost==2.0.3\npandas, numpy, matplotlib, seaborn\nCode repository: GitHub Repo Link\n\n\nModelling Pipeline\n\n\n\n\n\ngraph TD\n    A[Load Data] --&gt; B[Feature Engineering]\n    B --&gt; C[Split Data]\n    C --&gt; D1[Train LinearRegression]\n    C --&gt; D2[Train RandomForest]\n    C --&gt; D3[Train XGBoost]\n    D1 --&gt; E1[Evaluate Model]\n    D2 --&gt; E2[Evaluate Model]\n    D3 --&gt; E3[Evaluate Model]\n\n\n\n\n\n\n\n\nModel Artefacts\n\nRandomForest Model: random_forest_rent.pkl, random_forest_purchase.pkl\nConfiguration files: config.yml, params.json",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#rental-price-prediction",
    "href": "modelling_report.html#rental-price-prediction",
    "title": "Modelling Report",
    "section": "Rental Price Prediction",
    "text": "Rental Price Prediction\n\nLinear Regression\n\nRMSE: 855.18 CHF\n\nR²: 0.62\n\nPlots:\n\n\n\n\n\n\nXGBoost\n\nRMSE: 546.03 CHF\n\nR²: 0.83\n\nPlots:\n\n\n\n\n\n\nRandom Forest (Selected)\n\nRMSE: 188.42 CHF\n\nR²: 0.98\n\nPlots:",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#purchase-price-prediction",
    "href": "modelling_report.html#purchase-price-prediction",
    "title": "Modelling Report",
    "section": "Purchase Price Prediction",
    "text": "Purchase Price Prediction\n\nLinear Regression\n\nRMSE: 158’601.24 CHF\n\nR²: 0.58\n\nPlots:\n\n\n\n\n\n\nXGBoost\n\nRMSE: 91’578.85 CHF\n\nR²: 0.84\n\nPlots:\n\n\n\n\n\n\nRandom Forest (Selected)\n\nRMSE: 37’346.90 CHF\n\nR²: 0.97\n\nPlots:",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#semantic-text-clustering",
    "href": "modelling_report.html#semantic-text-clustering",
    "title": "Modelling Report",
    "section": "Semantic Text Clustering",
    "text": "Semantic Text Clustering\nTo enhance the predictive power of property descriptions, we introduced semantic clustering using the SentenceTransformer model all-MiniLM-L6-v2.\n\n\n\n\n\ngraph TD\n    A[Load Descriptions] --&gt; B[SentenceTransformer Embedding]\n    B --&gt; C[Run KMeans Clustering]\n    C --&gt; D[Evaluate with Silhouette Score]\n    D --&gt; E[Select Optimal Cluster Number]",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#cluster-top-terms",
    "href": "modelling_report.html#cluster-top-terms",
    "title": "Modelling Report",
    "section": "Cluster Top Terms",
    "text": "Cluster Top Terms\nClusters were labeled using top TF-IDF terms per cluster, translated for stakeholder readability.\nExample:",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#image-features",
    "href": "modelling_report.html#image-features",
    "title": "Modelling Report",
    "section": "Image Features",
    "text": "Image Features\nImages were embedded using ResNet50, reduced using PCA (100 components), and merged by ID into the model.\n\n\n\n\n\ngraph TD\n    A[Download Images] --&gt; B[ResNet50 Feature Extraction]\n    B --&gt; C[PCA Reduction]\n    C --&gt; D[Join with Main DataFrame]",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#feature-engineering-summary",
    "href": "modelling_report.html#feature-engineering-summary",
    "title": "Modelling Report",
    "section": "Feature Engineering Summary",
    "text": "Feature Engineering Summary\n\n\n\nFeature Source\nExample Features\n\n\n\n\nStructured\narea, log_area_sqm, is_top_floor\n\n\nSemantic Clusters\ndescription_cluster\n\n\nImage PCA\nimg_pca_0 … img_pca_99\n\n\nGeo Binning\nlat_bin, lon_bin\n\n\nAugmented\nrare class noise injection",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#were-the-objectives-achieved",
    "href": "modelling_report.html#were-the-objectives-achieved",
    "title": "Modelling Report",
    "section": "Were the Objectives Achieved?",
    "text": "Were the Objectives Achieved?\nYes. The enhanced Random Forest models surpassed baselines and proved suitable for deployment.",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#key-findings",
    "href": "modelling_report.html#key-findings",
    "title": "Modelling Report",
    "section": "Key Findings",
    "text": "Key Findings\n\nTree-based models outperformed linear models significantly\n\nCombined features led to robust predictions\n\nClustering added interpretability and segmentation",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#limitations",
    "href": "modelling_report.html#limitations",
    "title": "Modelling Report",
    "section": "Limitations",
    "text": "Limitations\n\nMarket dynamics not included in data\n\nClustering depends on text quality\n\nImage availability varies across properties",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#summary",
    "href": "modelling_report.html#summary",
    "title": "Modelling Report",
    "section": "Summary",
    "text": "Summary\n\nBest performance achieved with Random Forests using enriched feature sets\n\nPipeline supports automated, reproducible model training\n\nStakeholder interpretability was prioritized",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#future-work",
    "href": "modelling_report.html#future-work",
    "title": "Modelling Report",
    "section": "Future Work",
    "text": "Future Work\n\nUse external data (transport, demographics)\n\nExplore deep learning and model ensembles\n\nDeploy via REST API and monitor performance",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "md-templates/evaluation_decision_log.html",
    "href": "md-templates/evaluation_decision_log.html",
    "title": "Sample Project - Decision Log",
    "section": "",
    "text": "Sample Project - Decision Log\nThis protocol summarises the decisions from the evaluation of the data mining phase, which are made, for example, in a workshop together with the client and other stakeholders.\nDecide:\n\nDo results meet user needs?\nContinuation of the project yes/no\nPlanning of the deployment\nCarry out an additional data mining iteration\n\nAcquire more or different data\nImprovements in the modelling\nAddress governance issues\nor ethical considerations\n…\n\n\nAny presentation material created for such a workshop should also be stored in the docs folder.\nIt is important to list who was involved in the decisions and when they were made.\nThe structure and level of detail of this protocol should be tailored to the customs of the relevant organisation and the requirements of the decision-makers. It might include already a high level description of the envisioned product to be deployed."
  },
  {
    "objectID": "md-templates/data_report.html",
    "href": "md-templates/data_report.html",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "All information on the data used in the project is compiled in the data report in order to ensure the traceability and reproducibility of the results and to enable a systematic expansion of the database.\nTypically, in the exploratory analysis of the acquired raw data, quality and other issues are identified, which require pre-processing, merging of individual datasets and feature engineering into processed datasets. Therefore, this template provides a separate section for the processed data, which then serves as a starting point for the modelling activities. This needs to be adapted to the specific project requirements.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nQuelle\nStorage location\n\n\n\n\nDataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nDataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails of the data source/provider\nInformation on data procurement: description and possibly references to resources (download scripts, tools, online services, …). Any new team member should be able to acquire the data indepentendently following these instructions.\nLegal aspects of data use, licences, etc.\nData governance aspects: Categorisation of the data based on internal business requirements, e.g. public, business-relevant, personal\nIf applicable: categorisation into dependent (target variable, regressor) and independent (regressor) variables\n…\n\n\n\nThe data catalogue basically represents an extended schema of a relational database.\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nQuelle\nStorage location\n\n\n\n\nProcessed Dataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nProcessed Dataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails and reasons for the processing steps -&gt; Traceability and ensuring reproducibility\nHow can the data be accessed? Description, scripts, tools, …\n…\n\n\n\n\n\n\n\n\n\n\n…"
  },
  {
    "objectID": "md-templates/data_report.html#raw-data",
    "href": "md-templates/data_report.html#raw-data",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "Name\nQuelle\nStorage location\n\n\n\n\nDataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nDataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails of the data source/provider\nInformation on data procurement: description and possibly references to resources (download scripts, tools, online services, …). Any new team member should be able to acquire the data indepentendently following these instructions.\nLegal aspects of data use, licences, etc.\nData governance aspects: Categorisation of the data based on internal business requirements, e.g. public, business-relevant, personal\nIf applicable: categorisation into dependent (target variable, regressor) and independent (regressor) variables\n…\n\n\n\nThe data catalogue basically represents an extended schema of a relational database.\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\n\n\n\n\n\n\n2"
  },
  {
    "objectID": "md-templates/data_report.html#processed-data",
    "href": "md-templates/data_report.html#processed-data",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "Name\nQuelle\nStorage location\n\n\n\n\nProcessed Dataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nProcessed Dataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails and reasons for the processing steps -&gt; Traceability and ensuring reproducibility\nHow can the data be accessed? Description, scripts, tools, …\n…\n\n\n\n\n\n\n\n\n\n\n…"
  }
]